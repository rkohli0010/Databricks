{"cells":[{"cell_type":"markdown","source":["###MLOps: Assembling Pipelines"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b26d871b-c5c2-4f7e-92f5-093f15c4625a","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["In this project, our primary focus will be to create COLUMN TRANSFORMERS to clean data, and then create an ML PIPELINE to ensure whatever new data is fed into the model, goes through the pipeline and hence is fed into the model with required TRANSFORMATIONS!"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d370d802-705a-4bd8-9bd0-e2e7aa6d2ea3","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# notebook config\nUSER_NAME = dbutils.notebook.entry_point.getDbutils().notebook().getContext().tags().apply('user')\nFILE_STORE_ROOT = '/FileStore/shared_uploads/'+USER_NAME"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b7e4c39b-c094-47ed-a8c4-e9868ab76a64","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["spend = spark.read.csv(\n  FILE_STORE_ROOT+'/wholesale_customers/', \n  header=True, \n  inferSchema=True\n  )\n\nspend_df = spend.toPandas()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"70dab403-eb29-47cc-baa9-45ca9bbc91c5","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["WE NEED TO ENSURE THAT IN OUR PIPELINES WE ARE REFERENCING OUR COLUMNS BY INDICES RATHER THAN COLUMN NAMES, THIS IS VERY IMPORTANT CAUSE...\n1. After transformation through column transformers in the pipeline, the columns will be renamed to indices\n2. Also, as move towards model deployment, it's important to refer columns with indices rather than names"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4c10d2e3-05d9-436a-b8f8-afb6a0ca0d17","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.compose import ColumnTransformer\n\n# defining stages for ColumnTransformer\ntransformer = ColumnTransformer([\n  ('ohe_encoder', OneHotEncoder( drop='first', sparse=False), [0, 1]), # apply OHE to channel and region fields\n  ('robust_scaler', RobustScaler(), [2,3,4,5,6,7]) # apply robust scaler to all other fields\n  ])\n\n## applying transformations\n#X = transformer.fit_transform( spend_df )"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"48e93c48-6b2b-40d5-b85c-cebaef305324","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["from sklearn.cluster import KMeans\n\n# instantiating and configure clustering model\nkm = KMeans(\n  n_clusters=4, \n  init='random',\n  n_init=1000\n  )\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7bbeabb1-7658-4488-a47e-73a7ce1219b1","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Ideally, hyperparameter tuning should be done! Please refer to the other notebook for the same!"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d39bfa49-d1a4-4d0c-a022-3888f004e03e","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from sklearn.pipeline import Pipeline\n\n# combining transformations with model as a pipeline\nclf = Pipeline(\n  steps=[\n    ('transform', transformer),\n    ('clustering', km)\n    ]\n  )"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6d76bc71-5eae-4064-9f6c-925f4ccadaad","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Important Points...\n1. Inside a pipeline, steps will be executed in the order specified. Unlike a column transformer. Hence it's important to specify the steps correctly\n2. Indices for transformations have to be according to the initial dataset. Although after a column transformation column indices will be reset, the pipeline will refer to the original dataset for recognizing the columns"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"34cebed5-e6be-4f4d-be33-ff803fb1f31f","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from sklearn.metrics import silhouette_score\n\n# fitting the model\nclf.fit(spend_df)\n\n# generating a prediction\npredict = clf.predict(spend_df)\n\n# scoring the predictions\nprint( silhouette_score( spend_df, predict) )"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0e4f0f13-2f11-48cd-8050-32eb06475672","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["0.42248161797300304\n"]}],"execution_count":0},{"cell_type":"markdown","source":["Although the accuracy is not great, we were able to set a pipeline.\n\nPlease refer to my code below for a more complex pipeline -->"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"cad17a4f-00ca-4c84-897c-725c7982b8c1","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# after making data available at /dbfs/tmp/melbourne/melb_data.csv\ndf = spark.read.csv(\n  FILE_STORE_ROOT+'/melbourne_housing/melb_data.csv', \n  sep=',', \n  header=True,\n  inferSchema=True\n  ).toPandas()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1c214da1-06dc-498d-a085-7625fd7fea0f","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["import pandas as pd\nimport numpy as np\n\n\n# separating features from label column\nfeatures = df.drop('Price', axis=1)\nlabels = df['Price']"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"17bfcd88-f3b4-4cc8-813a-c14671a89870","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["With the Melbourne data loaded into two DataFrames, one representing our features and the other representing our labels, let's assemble our pipeline including the two steps for feature transformation. Notice again that we are not using field names but instead using positional references for our fields:"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a44d705f-75d8-460d-8c88-61bc16f62b8f","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["features"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"421a47af-a500-4ce5-975c-47228568fb87","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>handicap</th>\n      <th>water</th>\n      <th>adoption</th>\n      <th>medical</th>\n      <th>elsalvador</th>\n      <th>religion</th>\n      <th>satellite</th>\n      <th>nicraguan</th>\n      <th>missle</th>\n      <th>immigration</th>\n      <th>fuel</th>\n      <th>education</th>\n      <th>superfund</th>\n      <th>crime</th>\n      <th>exports</th>\n      <th>southafrica</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>430</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>431</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>432</th>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>433</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>434</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>435 rows × 16 columns</p>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>handicap</th>\n","      <th>water</th>\n","      <th>adoption</th>\n","      <th>medical</th>\n","      <th>elsalvador</th>\n","      <th>religion</th>\n","      <th>satellite</th>\n","      <th>nicraguan</th>\n","      <th>missle</th>\n","      <th>immigration</th>\n","      <th>fuel</th>\n","      <th>education</th>\n","      <th>superfund</th>\n","      <th>crime</th>\n","      <th>exports</th>\n","      <th>southafrica</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>430</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>431</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>432</th>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>433</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>434</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>435 rows × 16 columns</p>\n","</div>"]}}],"execution_count":0},{"cell_type":"code","source":["from sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.pipeline import Pipeline\n\n# defining stages for missing value ColumnTransformer\nmissing_value_transformer = ColumnTransformer([\n  (  'median_missing', \n      SimpleImputer(missing_values=np.NaN, strategy='median'), \n      [3,10,11,12,13,14,15]\n  ),\n  (  'most_frequent_missing', \n      SimpleImputer(missing_values=np.NaN, strategy='most_frequent'), \n      [4, 5]\n  )\n  ])\n\n# defining stages for encoding & scaling ColumnTransformer\nencoding_scaling_transformer = ColumnTransformer([\n  ('get my previously transformed stuff', 'passthrough', list(range(0,4))+[6]),\n  ('ohe_encode', OneHotEncoder( drop='first', sparse=False), [7, 8]),\n  ('normalize', RobustScaler(), [4, 5])\n  ])\n\n# instantiating and configure model\nreg = LinearRegression()\n\n# defining pipeline\nclf = Pipeline(steps=[\n  ('missing_values', missing_value_transformer),\n  ('encoding_scaling', encoding_scaling_transformer),\n  ('regression', reg)\n  ])"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f2d2a97f-7d63-43fb-8fa4-7f0c0a56a9ea","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["We now have a pipeline which applies two steps of data transformation before passing data to a linear regression model.  Let's now execute the pipeline to train and score our model:"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4ef3013d-ea00-4fb1-a192-cab52f389b67","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# fit the model\nclf.fit(features, labels)\n\n# make predictions\npredicted_prices = clf.predict(features)\n\n# calculate score\nprint( clf.score(features, labels) )"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a8614d7c-a47e-4579-9a08-7a4b99336c0c","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["0.35844407788242505\n"]}],"execution_count":0},{"cell_type":"markdown","source":["While not a great score, our Pipeline object allows us to manage a series of transformations in combination with our model, easing our logic management. \n\nThe most important reson for a pipeline in my opinion is to ensure whatever new data is fed into the model for predictions in the future goes through the required transformations to make it similar to the training data used!!!"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e6d78613-332b-472f-af13-56f9f588ad89","inputWidgets":{},"title":""}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"7.05 Pipelines","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
